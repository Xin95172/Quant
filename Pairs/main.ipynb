{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, coint\n",
    "from scipy.special import gamma\n",
    "from scipy.optimize import root, minimize\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from fetch_coint_fn import fetch_coint_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and get params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_params(series1, series2):\n",
    "    x_with_const = sm.add_constant(series2)\n",
    "    model = sm.OLS(series1, x_with_const)\n",
    "    results = model.fit()\n",
    "    intercept, beta = results.params\n",
    "    return intercept, beta\n",
    "\n",
    "def get_spread(series1, series2, beta):\n",
    "    spread = series1 - (beta * series2)\n",
    "    return spread\n",
    "\n",
    "def get_zscore(spread):\n",
    "    mean = np.mean(spread)\n",
    "    std = np.std(spread)\n",
    "    zscore = (spread - mean) / std\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_df(symbol1, symbol2, df1, df2):\n",
    "    if len(df1) != len(df2):\n",
    "        return None\n",
    "\n",
    "    raw_df = pd.DataFrame()\n",
    "\n",
    "    raw_df = pd.concat([df1, df2], axis = 1)\n",
    "    raw_df.columns = [\n",
    "        \"Timestamp\", f\"Open_{symbol1}\", f\"High_{symbol1}\", f\"Low_{symbol1}\", f\"Close_{symbol1}\", f\"Volume_{symbol1}\", f\"Turnover_{symbol1}\",\n",
    "        \"Timestamp\", f\"Open_{symbol2}\", f\"High_{symbol2}\", f\"Low_{symbol2}\", f\"Close_{symbol2}\", f\"Volume_{symbol2}\", f\"Turnover_{symbol2}\"\n",
    "        ]\n",
    "    raw_df = raw_df.loc[:,~raw_df.columns.duplicated()]\n",
    "    raw_df.set_index(\"Timestamp\", inplace = True)\n",
    "    raw_df.index = pd.to_datetime(raw_df.index)\n",
    "\n",
    "    raw_df[\"beta\"] = calculate_params(raw_df[f\"Close_{symbol1}\"], raw_df[f\"Close_{symbol2}\"])[1]\n",
    "    raw_df[\"spread\"] = get_spread(raw_df[f\"Close_{symbol1}\"], raw_df[f\"Close_{symbol2}\"], raw_df[\"beta\"])\n",
    "    Z = get_zscore(raw_df[\"spread\"])\n",
    "\n",
    "    raw_df[\"Entry_long\"] = Z < -2\n",
    "    raw_df[\"Exit_long\"] = Z >= -0.5\n",
    "    raw_df[\"Entry_short\"] = Z > 2\n",
    "    raw_df[\"Exit_short\"] = Z <= 0.75\n",
    "\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(raw_df, symbol1, symbol2, window_start = 0, window_end = None, Spot_fund = 10000):\n",
    "    if raw_df is None:\n",
    "        return None\n",
    "\n",
    "    if window_start == 0 and window_end is None:\n",
    "        testing_data = raw_df.copy()\n",
    "    else:\n",
    "        testing_data = raw_df.loc[window_start: window_end].copy()\n",
    "    \n",
    "    BS = None\n",
    "    cols_to_init = [f\"Spotsize_{symbol1}\", f\"Spotsize_{symbol2}\", \"Profit\", \"Profitfee\", \"cumReturn\", \"Drawdown\"]\n",
    "    testing_data[cols_to_init] = 0.0\n",
    "    \n",
    "    for i in range(len(testing_data)):\n",
    "        if i == len(testing_data) - 1:\n",
    "            break\n",
    "        \n",
    "        Timestamp = testing_data.index[i]\n",
    "        nextTimestamp = testing_data.index[i + 1]\n",
    "        if BS is None:\n",
    "            if testing_data[\"Entry_long\"].iloc[i]:\n",
    "                BS = \"B\"\n",
    "                testing_data.loc[nextTimestamp, f\"Spotsize_{symbol1}\"] = - (Spot_fund / 2) / testing_data[f\"Close_{symbol1}\"].iloc[i]\n",
    "                testing_data.loc[nextTimestamp, f\"Spotsize_{symbol2}\"] = (Spot_fund / 2) / testing_data[f\"Close_{symbol2}\"].iloc[i]\n",
    "\n",
    "            elif testing_data[\"Entry_short\"].iloc[i]:\n",
    "                BS = \"S\"\n",
    "                testing_data.loc[nextTimestamp, f\"Spotsize_{symbol1}\"] = (Spot_fund / 2) / testing_data[f\"Close_{symbol1}\"].iloc[i]\n",
    "                testing_data.loc[nextTimestamp, f\"Spotsize_{symbol2}\"] = - (Spot_fund / 2) / testing_data[f\"Close_{symbol2}\"].iloc[i]\n",
    "        \n",
    "        elif BS in [\"B\", \"S\"]:\n",
    "            testing_data.loc[nextTimestamp, f\"Spotsize_{symbol1}\"] = testing_data.loc[Timestamp, f\"Spotsize_{symbol1}\"]\n",
    "            testing_data.loc[nextTimestamp, f\"Spotsize_{symbol2}\"] = testing_data.loc[Timestamp, f\"Spotsize_{symbol2}\"]\n",
    "            testing_data.loc[Timestamp, \"Profit\"] = (testing_data.loc[nextTimestamp, f\"Open_{symbol1}\"] - testing_data.loc[Timestamp, f\"Open_{symbol1}\"]) * testing_data[f\"Spotsize_{symbol1}\"].iloc[i] + (testing_data.loc[nextTimestamp, f\"Open_{symbol2}\"] - testing_data.loc[Timestamp, f\"Open_{symbol2}\"]) * testing_data[f\"Spotsize_{symbol2}\"].iloc[i]\n",
    "            testing_data.loc[Timestamp, \"Profitfee\"] = testing_data.loc[Timestamp, \"Profit\"]\n",
    "            \n",
    "            if testing_data[\"Exit_long\"].iloc[i] | testing_data[\"Exit_short\"].iloc[i]:\n",
    "                BS = None\n",
    "                testing_data.loc[nextTimestamp, f\"Spotsize_{symbol1}\"] = 0\n",
    "                testing_data.loc[nextTimestamp, f\"Spotsize_{symbol2}\"] = 0\n",
    "\n",
    "    testing_data[\"cumReturn\"] = testing_data[\"Profitfee\"].cumsum()\n",
    "    peak = testing_data[\"cumReturn\"].cummax()\n",
    "    testing_data[\"Drawdown\"] = - (testing_data[\"cumReturn\"] - peak) / peak\n",
    "\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(df, cost, freq_per_day = 24):\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    performance = {}\n",
    "    profit_series = df[\"Profitfee\"].dropna()\n",
    "    negative_profit = profit_series[profit_series < 0]\n",
    "    positive_profit = profit_series[profit_series > 0]\n",
    "\n",
    "    performance[\"totalReturn\"] = df[\"Profit\"].sum()\n",
    "    performance[\"totalProfitfee\"] = df[\"Profitfee\"].sum()\n",
    "    performance[\"AnnualizedReturn\"] = profit_series.mean() * freq_per_day * 365\n",
    "    performance[\"Win Rate\"] = len(positive_profit) / len(profit_series) if len(profit_series) != 0 else 0\n",
    "    performance[\"SharpeRatio\"] = profit_series.mean() / profit_series.std() if profit_series.std() != 0 else np.nan\n",
    "    performance[\"SortinoRatio\"] = profit_series.mean() / negative_profit.std() if negative_profit.std() != 0 else np.nan\n",
    "    performance[\"ProfitFactor\"] = positive_profit.sum() / abs(negative_profit.sum()) if abs(negative_profit.sum()) != 0 else np.inf\n",
    "    performance[\"MaxDrawdown\"] = df[\"Drawdown\"].min()\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_main_df(df, symbol1, symbol2):\n",
    "    new_main_df = df[[\"Profit\", \"Profitfee\", \"cumReturn\", \"Drawdown\"]].copy()\n",
    "    new_main_df[\"Timestamp\"] = df.index\n",
    "    new_main_df[\"Pairs\"] = (symbol1 + \" - \" + symbol2)\n",
    "    new_main_df[\"Pairs\"] = new_main_df[\"Pairs\"].astype(\"category\")\n",
    "\n",
    "    cols = [\"Pairs\", \"Profit\", \"Profitfee\", \"cumReturn\", \"Drawdown\"]\n",
    "    new_main_df = new_main_df[cols]\n",
    "\n",
    "    return new_main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling(main_df, train_ratio, n_window, spot_sector_map, spot_folder, cost, focus_indicator = \"totalReturn\"):\n",
    "    \"\"\"\n",
    "    有時候不能整除，所以可能會多一個window\n",
    "    \"\"\"\n",
    "    total_size = len(main_df)\n",
    "    test_ratio = 1 - train_ratio\n",
    "    \n",
    "    window = total_size // (1 + test_ratio * (n_window - 1))\n",
    "    train_size = int(window * train_ratio)\n",
    "    test_size = int(window * test_ratio)\n",
    "\n",
    "    start = 0\n",
    "    window_num = 0\n",
    "    train_results = []\n",
    "\n",
    "    while start + train_size + test_size <= total_size:\n",
    "        print(f\"Processing window {window_num + 1}\")\n",
    "\n",
    "        train = main_df.iloc[start : start + train_size]\n",
    "        train_start_time = train.index[0]\n",
    "        train_end_time = train.index[-1]\n",
    "        print(f\"{train_start_time}-{train_end_time}\")\n",
    "        \n",
    "        # fetch cointegrated pairs by parralel processing(8 workers)\n",
    "        coint_pairs = fetch_coint_pairs(spot_sector_map, spot_folder, train_start_time, train_end_time)\n",
    "        for pair_data in coint_pairs:\n",
    "            sector = pair_data[\"sector\"]\n",
    "            symbol1, symbol2 = pair_data[\"pair\"][0], pair_data[\"pair\"][1]\n",
    "\n",
    "            df1 = pd.read_csv(f\"{spot_folder}/{symbol1}.csv\")\n",
    "            df2 = pd.read_csv(f\"{spot_folder}/{symbol2}.csv\")\n",
    "            raw_df = get_raw_df(symbol1, symbol2, df1, df2)\n",
    "            training_df = backtest(raw_df, symbol1, symbol2, train_start_time, train_end_time)\n",
    "            if training_df is None:\n",
    "                continue\n",
    "            performance = get_performance(training_df, cost)\n",
    "            train_results.append({\n",
    "                \"sector\": sector,\n",
    "                \"pair\": (symbol1, symbol2),\n",
    "                \"performance\": performance\n",
    "            })\n",
    "\n",
    "        sorted_results = sorted(train_results, key = lambda x: x[\"performance\"][focus_indicator], reverse = True)\n",
    "        sorted_df = pd.DataFrame(sorted_results)\n",
    "        sorted_df.to_csv(\"sorted_results.csv\")\n",
    "        best_pair = sorted_results[0]\n",
    "        symbol1, symbol2 = best_pair[\"pair\"][0], best_pair[\"pair\"][1]\n",
    "\n",
    "        test = main_df.iloc[start + train_size : start + train_size + test_size]\n",
    "        testing_start_time = test.index[0]\n",
    "        testing_end_time = test.index[-1]\n",
    "\n",
    "        df1 = pd.read_csv(f\"{spot_folder}/{symbol1}.csv\")\n",
    "        df2 = pd.read_csv(f\"{spot_folder}/{symbol2}.csv\")\n",
    "        raw_df = get_raw_df(symbol1, symbol2, df1, df2)        \n",
    "        testing_df = backtest(raw_df, symbol1, symbol2, testing_start_time, testing_end_time)\n",
    "        if testing_df is None:\n",
    "            continue\n",
    "        performance = get_performance(testing_df, cost)\n",
    "        \n",
    "        new_main_df = get_new_main_df(testing_df, symbol1, symbol2)\n",
    "        main_df = pd.concat([main_df, new_main_df], axis = 0)\n",
    "\n",
    "        start += test_size\n",
    "        window_num += 1\n",
    "\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_sector = \"/Users/xinc./Documents/GitHub/Quant/data/crypto_database/metadata/spot_sector_map.json\"\n",
    "spot_folder = \"/Users/xinc./Documents/GitHub/Quant/data/crypto_database/spot\"\n",
    "\n",
    "with open(spot_sector, \"r\") as f:\n",
    "    spot_sector_map = json.load(f)\n",
    "\n",
    "start = \"2023-01-01 00:00:00+08:00\"\n",
    "end = \"2023-10-01 00:00:00+08:00\"\n",
    "main_df = pd.DataFrame(index = pd.date_range(start, end, freq = \"h\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing window 1\n",
      "2023-01-01 00:00:00+08:00-2023-07-11 02:00:00+08:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 19/2701 [00:07<09:11,  4.86it/s] Process SpawnPoolWorker-16:\n",
      "Process SpawnPoolWorker-15:\n",
      "Process SpawnPoolWorker-12:\n",
      "Process SpawnPoolWorker-13:\n",
      "  1%|          | 19/2701 [00:07<18:21,  2.44it/s]\n",
      "Process SpawnPoolWorker-10:\n",
      "Process SpawnPoolWorker-9:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main_df \u001b[38;5;241m=\u001b[39m \u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspot_sector_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspot_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m main_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_df.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m, in \u001b[0;36mrolling\u001b[0;34m(main_df, train_ratio, n_window, spot_sector_map, spot_folder, cost, focus_indicator)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_start_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_end_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# fetch cointegrated pairs by parralel processing(8 workers)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m coint_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_coint_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspot_sector_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspot_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_start_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_end_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair_data \u001b[38;5;129;01min\u001b[39;00m coint_pairs:\n\u001b[1;32m     27\u001b[0m     sector \u001b[38;5;241m=\u001b[39m pair_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msector\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/Quant/TMBA/Pairs/fetch_coint_fn.py:59\u001b[0m, in \u001b[0;36mfetch_coint_pairs\u001b[0;34m(sector_map, spot_folder, start_time, end_time, max_workers)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     58\u001b[0m     fn \u001b[38;5;241m=\u001b[39m partial(process_pair, spot_folder \u001b[38;5;241m=\u001b[39m spot_folder, start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(start_time), end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(end_time))\n\u001b[0;32m---> 59\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair_info \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pair_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_df = rolling(main_df, 0.7, 1, spot_sector_map, spot_folder, 0.0005)\n",
    "main_df.to_csv(\"main_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
