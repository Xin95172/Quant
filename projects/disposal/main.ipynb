{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3c3b715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"/Users/xinc./Documents/GitHub/note\")\n",
    "sys.path.append(os.getcwd()) # 加入目前路徑以匯入 utils\n",
    "\n",
    "from module.get_info_Postgre import PostgresClient\n",
    "from module.get_info_FinMind import FinMindClient\n",
    "from module.plot_func import plot\n",
    "from utils import batch_fetch_prices, run_event_study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0aee6",
   "metadata": {},
   "source": [
    "# read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ebc628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料庫中的 disposal_info 表格\n",
    "database_name = \"disposal\"\n",
    "client = PostgresClient(database = database_name)\n",
    "disposal_info = client.fetch_table(table ='disposal_info', date_col='date', start_date='2018-01-01', end_date='2025-12-31', order_by='date')\n",
    "disposal_info = disposal_info.loc[disposal_info[\"is_disposal\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92998fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>is_disposal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1475</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2424</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3219</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>911616</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>8287</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641466</th>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>2515</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641784</th>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>8358</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641952</th>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>6488</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642278</th>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>3163</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642294</th>\n",
       "      <td>2025-11-11</td>\n",
       "      <td>3081</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date stock_id  is_disposal\n",
       "121     2018-01-01     1475         True\n",
       "289     2018-01-01     2424         True\n",
       "1235    2018-01-01     3219         True\n",
       "1493    2018-01-01   911616         True\n",
       "1506    2018-01-01     8287         True\n",
       "...            ...      ...          ...\n",
       "7641466 2025-11-11     2515         True\n",
       "7641784 2025-11-11     8358         True\n",
       "7641952 2025-11-11     6488         True\n",
       "7642278 2025-11-11     3163         True\n",
       "7642294 2025-11-11     3081         True\n",
       "\n",
       "[36512 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disposal_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fetch_finmind_price",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 895 unique stocks with disposal events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching by Stock: 100%|██████████| 895/895 [02:50<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 33450 price rows.\n",
      "        Date Stock_id   Open   High    Low  Close  Volume  TradingAmount\n",
      "0 2017-12-29     1475  48.00  53.30  48.00  50.00  901560       45481144\n",
      "1 2018-01-02     1475  48.20  48.20  45.00  45.00  169974        7779259\n",
      "2 2018-01-03     1475  45.10  48.00  45.10  45.85   87200        4039709\n",
      "3 2018-01-04     1475  46.95  47.95  46.00  46.80   65042        3053813\n",
      "4 2018-01-05     1475  46.00  46.30  45.75  46.05   52010        2386158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Optimization] 使用平行化抓取加速下載\n",
    "# 關閉 Log 避免洗版\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"WARNING\")\n",
    "\n",
    "fm_client = FinMindClient()\n",
    "price_df = batch_fetch_prices(fm_client, disposal_info, max_workers=10)\n",
    "\n",
    "if not price_df.empty:\n",
    "    print(price_df.head())\n",
    "else:\n",
    "    print(\"No price data fetched.\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e98b30",
   "metadata": {},
   "source": [
    "## Analysis: Event Study on Disposal Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "595f1589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Event Study Analysis...\n",
      "Original events: 36512, Consolidated Start Events: 2192\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Close', 'Volume'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Event Study Analysis (Using Optimized Module) ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m event_study_df = \u001b[43mrun_event_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisposal_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event_study_df.empty:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(event_study_df[[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mStock_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mt_label\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgap_days\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcalendar_relative_day\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mClose\u001b[39m\u001b[33m'\u001b[39m]].head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Quant/projects/disposal/utils.py:45\u001b[39m, in \u001b[36mrun_event_study\u001b[39m\u001b[34m(price_df, disposal_info, offset_days)\u001b[39m\n\u001b[32m     43\u001b[39m     d_start = event_date - timedelta(days=offset_days)\n\u001b[32m     44\u001b[39m     d_end = event_date + timedelta(days=offset_days)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     mask |= (price_dates >= d_start) & (price_dates <= d_end)\n\u001b[32m     47\u001b[39m filtered_df = price_df[mask].copy()\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filtered_df.empty:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quant_mac/lib/python3.13/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quant_mac/lib/python3.13/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/quant_mac/lib/python3.13/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Close', 'Volume'] not in index\""
     ]
    }
   ],
   "source": [
    "# --- Event Study Analysis (Using Optimized Module) ---\n",
    "\n",
    "event_study_df = run_event_study(price_df, disposal_info)\n",
    "\n",
    "if not event_study_df.empty:\n",
    "    print(event_study_df[['Date', 'Stock_id', 't_label', 'gap_days', 'calendar_relative_day', 'Close']].head(10))\n",
    "    \n",
    "    # 寫入 CSV 方便檢查\n",
    "    event_study_df.to_csv('test.csv', index=False)\n",
    "else:\n",
    "    print(\"Analysis returned empty DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
